<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>helper.classification API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>helper.classification</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np

from pandas import DataFrame, Series, concat
from sklearn.metrics import (
    log_loss,
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
)
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from statsmodels.stats.outliers_influence import variance_inflation_factor
from scipy.stats import norm

from helper.util import my_pretty_table
from helper.plot import (
    my_learing_curve,
    my_confusion_matrix,
    my_roc_curve,
    my_pr_curve,
    my_roc_pr_curve,
)


def my_logistic_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    cv: int = 5,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    params: dict = {
        &#34;penalty&#34;: [&#34;l1&#34;, &#34;l2&#34;, &#34;elasticnet&#34;],
        &#34;C&#34;: [0.001, 0.01, 0.1, 1, 10, 100],
    },
) -&gt; LogisticRegression:
    &#34;&#34;&#34;로지스틱 회귀분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        params (dict, optional): 하이퍼파라미터. Defaults to {&#39;penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;, &#39;elasticnet&#39;], &#39;C&#39;: [0.001, 0.01, 0.1, 1, 10, 100]}.
    Returns:
        LogisticRegression: 회귀분석 모델
    &#34;&#34;&#34;
    # ------------------------------------------------------
    # 분석모델 생성

    # 교차검증 설정
    if cv &gt; 0:
        prototype_estimator = LogisticRegression(max_iter=500, n_jobs=-1)
        grid = GridSearchCV(prototype_estimator, param_grid=params, cv=cv, n_jobs=-1)
        grid.fit(x_train, y_train)

        result_df = DataFrame(grid.cv_results_[&#34;params&#34;])
        result_df[&#34;mean_test_score&#34;] = grid.cv_results_[&#34;mean_test_score&#34;]

        print(&#34;[교차검증]&#34;)
        my_pretty_table(
            result_df.dropna(subset=[&#34;mean_test_score&#34;]).sort_values(
                by=&#34;mean_test_score&#34;, ascending=False
            )
        )
        print(&#34;&#34;)

        estimator = grid.best_estimator_
        estimator.best_params = grid.best_params_
    else:
        estimator = LogisticRegression(max_iter=500, n_jobs=-1)
        estimator.fit(x_train, y_train)

    # ------------------------------------------------------
    # 결과값 생성

    # 훈련 데이터에 대한 추정치 생성
    y_pred = (
        estimator.predict(x_test) if x_test is not None else estimator.predict(x_train)
    )
    y_pred_prob = (
        estimator.predict_proba(x_test)
        if x_test is not None
        else estimator.predict_proba(x_train)
    )

    # 도출된 결과를 모델 객체에 포함시킴
    estimator.x = x_test if x_test is not None else x_train
    estimator.y = y_test if y_test is not None else y_train
    estimator.y_pred = y_pred if y_test is not None else estimator.predict(x_train)
    estimator.y_pred_proba = (
        y_pred_prob if y_test is not None else estimator.predict_proba(x_train)
    )

    # ------------------------------------------------------
    # 성능평가
    if x_test is not None and y_test is not None:
        my_classification_result(
            estimator,
            x_train=x_train,
            y_train=y_train,
            x_test=x_test,
            y_test=y_test,
            learning_curve=learning_curve,
            cv=cv,
            figsize=figsize,
            dpi=dpi,
        )
    else:
        my_classification_result(
            estimator,
            x_train=x_train,
            y_train=y_train,
            learning_curve=learning_curve,
            cv=cv,
            figsize=figsize,
            dpi=dpi,
        )

    # ------------------------------------------------------
    # 보고서 출력
    if report:
        my_classification_report(estimator, x_train, y_train, x_test, y_test, sort)

    return estimator


def my_classification_result(
    estimator: any,
    x_train: DataFrame = None,
    y_train: Series = None,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve: bool = True,
    cv: int = 10,
    figsize: tuple = (12, 5),
    dpi: int = 100,
) -&gt; None:
    &#34;&#34;&#34;회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법(ovo, ovr, None). Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to False.
        cv (int, optional): 교차검증 횟수. Defaults to 10.
        figsize (tuple, optional): 그래프의 크기. Defaults to (12, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
    &#34;&#34;&#34;

    # ------------------------------------------------------
    # 성능평가

    scores = []
    score_names = []

    # 이진분류인지 다항분류인지 구분
    labels = list(y_train.unique())
    is_binary = len(labels) == 2

    if x_train is not None and y_train is not None:
        # 추정치
        y_train_pred = estimator.predict(x_train)
        y_train_pred_proba = estimator.predict_proba(x_train)
        y_train_pred_proba_1 = y_train_pred_proba[:, 1]

        # 의사결정계수 --&gt; 다항로지스틱에서는 사용 X
        if is_binary:
            y_train_log_loss_test = -log_loss(
                y_train, y_train_pred_proba, normalize=False
            )
            y_train_null = np.ones_like(y_train) * y_train.mean()
            y_train_log_loss_null = -log_loss(y_train, y_train_null, normalize=False)
            y_train_pseudo_r2 = 1 - (y_train_log_loss_test / y_train_log_loss_null)

        # 혼동행렬
        y_train_conf_mat = confusion_matrix(y_train, y_train_pred)

        if is_binary:
            # TN,FP,FN,TP --&gt; 다항로지스틱에서는 사용 X
            ((TN, FP), (FN, TP)) = y_train_conf_mat

            # 성능평가
            # 의사결정계수, 위양성율, 특이성, AUC는 다항로지스틱에서는 사용 불가
            # 나머지 항목들은 코드 변경 예정
            result = {
                &#34;의사결정계수(Pseudo R2)&#34;: y_train_pseudo_r2,
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_train, y_train_pred),
                &#34;정밀도(Precision)&#34;: precision_score(y_train, y_train_pred),
                &#34;재현율(Recall)&#34;: recall_score(y_train, y_train_pred),
                &#34;위양성율(Fallout)&#34;: FP / (TN + FP),
                &#34;특이성(TNR)&#34;: 1 - (FP / (TN + FP)),
                &#34;F1 Score&#34;: f1_score(y_train, y_train_pred),
                &#34;AUC&#34;: roc_auc_score(y_train, y_train_pred_proba_1),
            }
        else:
            result = {
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_train, y_train_pred),
                &#34;정밀도(Precision)&#34;: precision_score(
                    y_train, y_train_pred, average=&#34;macro&#34;
                ),
                &#34;재현율(Recall)&#34;: recall_score(y_train, y_train_pred, average=&#34;macro&#34;),
                &#34;F1 Score&#34;: f1_score(y_train, y_train_pred, average=&#34;macro&#34;),
                &#34;AUC(ovo)&#34;: roc_auc_score(
                    y_train, y_train_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovo&#34;
                ),
                &#34;AUC(ovr)&#34;: roc_auc_score(
                    y_train, y_train_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovr&#34;
                ),
            }
        scores.append(result)
        score_names.append(&#34;훈련데이터&#34;)

    if x_test is not None and y_test is not None:
        # 추정치
        y_test_pred = estimator.predict(x_test)
        y_test_pred_proba = estimator.predict_proba(x_test)
        y_test_pred_proba_1 = y_test_pred_proba[:, 1]

        if is_binary:
            # 의사결정계수
            y_test_log_loss_test = -log_loss(y_test, y_test_pred_proba, normalize=False)
            y_test_null = np.ones_like(y_test) * y_test.mean()
            y_test_log_loss_null = -log_loss(y_test, y_test_null, normalize=False)
            y_test_pseudo_r2 = 1 - (y_test_log_loss_test / y_test_log_loss_null)

        # 혼동행렬
        y_test_conf_mat = confusion_matrix(y_test, y_test_pred)

        if is_binary:
            # TN,FP,FN,TP
            ((TN, FP), (FN, TP)) = y_test_conf_mat

            # 성능평가
            result = {
                &#34;의사결정계수(Pseudo R2)&#34;: y_test_pseudo_r2,
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_test, y_test_pred),
                &#34;정밀도(Precision)&#34;: precision_score(y_test, y_test_pred),
                &#34;재현율(Recall)&#34;: recall_score(y_test, y_test_pred),
                &#34;위양성율(Fallout)&#34;: FP / (TN + FP),
                &#34;특이성(TNR)&#34;: 1 - (FP / (TN + FP)),
                &#34;F1 Score&#34;: f1_score(y_test, y_test_pred),
                &#34;AUC&#34;: roc_auc_score(y_test, y_test_pred_proba_1),
            }
        else:
            result = {
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_test, y_test_pred),
                &#34;정밀도(Precision)&#34;: precision_score(
                    y_test, y_test_pred, average=&#34;macro&#34;
                ),
                &#34;재현율(Recall)&#34;: recall_score(y_test, y_test_pred, average=&#34;macro&#34;),
                &#34;F1 Score&#34;: f1_score(y_test, y_test_pred, average=&#34;macro&#34;),
                &#34;AUC(ovo)&#34;: roc_auc_score(
                    y_test, y_test_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovo&#34;
                ),
                &#34;AUC(ovr)&#34;: roc_auc_score(
                    y_test, y_test_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovr&#34;
                ),
            }

        scores.append(result)
        score_names.append(&#34;검증데이터&#34;)

    if is_binary:
        # 각 항목의 설명 추가
        result = {
            &#34;의사결정계수(Pseudo R2)&#34;: &#34;로지스틱회귀의 성능 측정 지표로, 1에 가까울수록 좋은 모델&#34;,
            &#34;정확도(Accuracy)&#34;: &#34;예측 결과(TN,FP,TP,TN)가 실제 결과(TP,TN)와 일치하는 정도&#34;,
            &#34;정밀도(Precision)&#34;: &#34;양성으로 예측한 결과(TP,FP) 중 실제 양성(TP)인 비율&#34;,
            &#34;재현율(Recall)&#34;: &#34;실제 양성(TP,FN) 중 양성(TP)으로 예측한 비율&#34;,
            &#34;위양성율(Fallout)&#34;: &#34;실제 음성(FP,TN) 중 양성(FP)으로 잘못 예측한 비율&#34;,
            &#34;특이성(TNR)&#34;: &#34;실제 음성(FP,TN) 중 음성(TN)으로 정확히 예측한 비율&#34;,
            &#34;F1 Score&#34;: &#34;정밀도와 재현율의 조화평균&#34;,
            &#34;AUC&#34;: &#34;ROC Curve의 밑면적으로, 1에 가까울수록 좋은 모델&#34;,
        }
    else:
        result = {
            &#34;정확도(Accuracy)&#34;: &#34;예측 결과(TN,FP,TP,TN)가 실제 결과(TP,TN)와 일치하는 정도&#34;,
            &#34;정밀도(Precision)&#34;: &#34;양성으로 예측한 결과(TP,FP) 중 실제 양성(TP)인 비율&#34;,
            &#34;재현율(Recall)&#34;: &#34;실제 양성(TP,FN) 중 양성(TP)으로 예측한 비율&#34;,
            &#34;F1 Score&#34;: &#34;정밀도와 재현율의 조화평균&#34;,
            &#34;AUC(ovo)&#34;: &#34;ROC Curve의 밑면적으로, 1에 가까울수록 좋은 모델&#34;,
            &#34;AUC(ovr)&#34;: &#34;ROC Curve의 밑면적으로, 1에 가까울수록 좋은 모델&#34;,
        }

    scores.append(result)
    score_names.append(&#34;설명&#34;)

    print(&#34;[분류분석 성능평가]&#34;)
    result_df = DataFrame(scores, index=score_names)
    my_pretty_table(result_df.T)

    # ------------------------------------------------------
    # 혼동행렬
    if conf_matrix:
        print(&#34;\n[혼동행렬]&#34;)

        if x_test is not None and y_test is not None:
            my_confusion_matrix(y_test, y_test_pred, figsize=figsize, dpi=dpi)
        else:
            my_confusion_matrix(y_train, y_train_pred, figsize=figsize, dpi=dpi)

    # ------------------------------------------------------
    # curve
    print(&#34;\n[Roc Curve]&#34;)

    if x_test is None or y_test is None:
        my_roc_curve(
            estimator,
            x_train,
            y_train,
            hist=hist,
            roc=roc,
            pr=pr,
            multiclass=multiclass,
            dpi=dpi,
        )
    else:
        my_roc_curve(
            estimator,
            x_test,
            y_test,
            hist=hist,
            roc=roc,
            pr=pr,
            multiclass=multiclass,
            dpi=dpi,
        )
    # 학습곡선
    if learning_curve:
        print(&#34;\n[학습곡선]&#34;)
        yname = y_train.name

        if x_test is not None and y_test is not None:
            y_df = concat([y_train, y_test])
            x_df = concat([x_train, x_test])
        else:
            y_df = y_train.copy()
            x_df = x_train.copy()

        x_df[yname] = y_df
        x_df.sort_index(inplace=True)

        if cv &gt; 0:
            my_learing_curve(
                estimator, data=x_df, yname=yname, cv=cv, figsize=figsize, dpi=dpi
            )
        else:
            my_learing_curve(
                estimator, data=x_df, yname=yname, figsize=figsize, dpi=dpi
            )


def my_classification_report(
    estimator: any,
    x_train: DataFrame = None,
    y_train: Series = None,
    x_test: DataFrame = None,
    y_test: Series = None,
    sort: str = None,
) -&gt; None:
    &#34;&#34;&#34;분류분석 결과를 이항분류와 다항분류로 구분하여 출력한다. 훈련데이터와 검증데이터가 함께 전달 될 경우 검증 데이터를 우선한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame, optional): 훈련 데이터의 독립변수. Defaults to None.
        y_train (Series, optional): 훈련 데이터의 종속변수. Defaults to None.
        x_test (DataFrame, optional): 검증 데이터의 독립변수. Defaults to None.
        y_test (Series, optional): 검증 데이터의 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    is_binary = len(estimator.classes_) == 2

    if is_binary:
        if x_test is not None and y_test is not None:
            my_classification_binary_report(estimator, x=x_test, y=y_test, sort=sort)
        else:
            my_classification_binary_report(estimator, x=x_train, y=y_train, sort=sort)
    else:
        if x_test is not None and y_test is not None:
            my_classification_multiclass_report(
                estimator, x=x_test, y=y_test, sort=sort
            )
        else:
            my_classification_multiclass_report(
                estimator, x=x_train, y=y_train, sort=sort
            )


def my_classification_binary_report(
    estimator: any, x: DataFrame = None, y: Series = None
) -&gt; None:
    &#34;&#34;&#34;이항로지스틱 회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x (DataFrame, optional): 독립변수. Defaults to None.
        y (Series, optional): 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    # 추정 확률
    y_pred_proba = estimator.predict_proba(x)

    # 추정확률의 길이(=샘플수)
    n = len(y_pred_proba)

    # 계수의 수 + 1(절편)
    m = len(estimator.coef_[0]) + 1

    # 절편과 계수를 하나의 배열로 결합
    coefs = np.concatenate([estimator.intercept_, estimator.coef_[0]])

    # 상수항 추가
    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis=1))

    # 변수의 길이를 활용하여 모든 값이 0인 행렬 생성
    ans = np.zeros((m, m))

    # 표준오차
    for i in range(n):
        ans += (
            np.dot(np.transpose(x_full[i, :]), x_full[i, :])
            * y_pred_proba[i, 1]
            * y_pred_proba[i, 0]
        )

    vcov = np.linalg.inv(np.matrix(ans))
    se = np.sqrt(np.diag(vcov))

    # t값
    t = coefs / se

    # p-value
    p_values = (1 - norm.cdf(abs(t))) * 2

    # VIF
    if len(x.columns) &gt; 1:
        vif = [
            variance_inflation_factor(x, list(x.columns).index(v))
            for i, v in enumerate(x.columns)
        ]
    else:
        vif = 0

    # 결과표 생성
    xnames = estimator.feature_names_in_

    result_df = DataFrame(
        {
            &#34;종속변수&#34;: [y.name] * len(xnames),
            &#34;독립변수&#34;: xnames,
            &#34;B(비표준화 계수)&#34;: np.round(estimator.coef_[0], 4),
            &#34;표준오차&#34;: np.round(se[1:], 3),
            &#34;t&#34;: np.round(t[1:], 4),
            &#34;유의확률&#34;: np.round(p_values[1:], 3),
            &#34;VIF&#34;: vif,
            &#34;OddsRate&#34;: np.round(np.exp(estimator.coef_[0]), 4),
        }
    )

    result_df.sort_values(&#34;VIF&#34;, ascending=False, inplace=True)

    my_pretty_table(result_df)


def my_classification_multiclass_report(
    estimator: any,
    x: DataFrame = None,
    y: Series = None,
    sort: str = None,
) -&gt; None:
    &#34;&#34;&#34;다중로지스틱 회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x (DataFrame, optional): 독립변수. Defaults to None.
        y (Series, optional): 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    class_list = list(estimator.classes_)
    class_size = len(class_list)

    # 추정 확률
    y_pred_proba = estimator.predict_proba(x)

    # 추정확률의 길이(=샘플수)
    n = len(y_pred_proba)

    for i in range(0, class_size):
        # 계수의 수 + 1(절편)
        m = len(estimator.coef_[i]) + 1

        # 절편과 계수를 하나의 배열로 결합
        coefs = np.concatenate([[estimator.intercept_[i]], estimator.coef_[i]])

        # 상수항 추가
        x_full = np.matrix(np.insert(np.array(x), 0, 1, axis=1))

        # 변수의 길이를 활용하여 모든 값이 0인 행렬 생성
        ans = np.zeros((m, m))

        # 표준오차
        for j in range(n):
            ans = (
                ans
                + np.dot(np.transpose(x_full[j, :]), x_full[j, :]) * y_pred_proba[j, i]
            )

        vcov = np.linalg.inv(np.matrix(ans))
        se = np.sqrt(np.diag(vcov))

        # t값
        t = coefs / se

        # p-value
        p_values = (1 - norm.cdf(abs(t))) * 2

        # VIF
        if len(x.columns) &gt; 1:
            vif = [
                variance_inflation_factor(x, list(x.columns).index(v))
                for i, v in enumerate(x.columns)
            ]
        else:
            vif = 0

        # 결과표 생성
        xnames = estimator.feature_names_in_

        result_df = DataFrame(
            {
                &#34;종속변수&#34;: [y.name] * len(xnames),
                &#34;CLASS&#34;: [class_list[i]] * len(xnames),
                &#34;독립변수&#34;: xnames,
                &#34;B(계수)&#34;: np.round(estimator.coef_[i], 4),
                &#34;표준오차&#34;: np.round(se[1:], 3),
                &#34;t&#34;: np.round(t[1:], 4),
                &#34;유의확률&#34;: np.round(p_values[1:], 3),
                &#34;VIF&#34;: vif,
                &#34;OddsRate&#34;: np.round(np.exp(estimator.coef_[i]), 4),
            }
        )

        if sort:
            if sort.upper() == &#34;V&#34;:
                result_df.sort_values(&#34;VIF&#34;, inplace=True)
            elif sort.upper() == &#34;P&#34;:
                result_df.sort_values(&#34;유의확률&#34;, inplace=True)
                pass

        my_pretty_table(result_df)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="helper.classification.my_classification_binary_report"><code class="name flex">
<span>def <span class="ident">my_classification_binary_report</span></span>(<span>estimator: <built-in function any>, x: pandas.core.frame.DataFrame = None, y: pandas.core.series.Series = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>이항로지스틱 회귀분석 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator</code></strong> :&ensp;<code>any</code></dt>
<dd>분류분석 추정기 (모델 객체)</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>독립변수. Defaults to None.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>종속변수. Defaults to None.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification_binary_report(
    estimator: any, x: DataFrame = None, y: Series = None
) -&gt; None:
    &#34;&#34;&#34;이항로지스틱 회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x (DataFrame, optional): 독립변수. Defaults to None.
        y (Series, optional): 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    # 추정 확률
    y_pred_proba = estimator.predict_proba(x)

    # 추정확률의 길이(=샘플수)
    n = len(y_pred_proba)

    # 계수의 수 + 1(절편)
    m = len(estimator.coef_[0]) + 1

    # 절편과 계수를 하나의 배열로 결합
    coefs = np.concatenate([estimator.intercept_, estimator.coef_[0]])

    # 상수항 추가
    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis=1))

    # 변수의 길이를 활용하여 모든 값이 0인 행렬 생성
    ans = np.zeros((m, m))

    # 표준오차
    for i in range(n):
        ans += (
            np.dot(np.transpose(x_full[i, :]), x_full[i, :])
            * y_pred_proba[i, 1]
            * y_pred_proba[i, 0]
        )

    vcov = np.linalg.inv(np.matrix(ans))
    se = np.sqrt(np.diag(vcov))

    # t값
    t = coefs / se

    # p-value
    p_values = (1 - norm.cdf(abs(t))) * 2

    # VIF
    if len(x.columns) &gt; 1:
        vif = [
            variance_inflation_factor(x, list(x.columns).index(v))
            for i, v in enumerate(x.columns)
        ]
    else:
        vif = 0

    # 결과표 생성
    xnames = estimator.feature_names_in_

    result_df = DataFrame(
        {
            &#34;종속변수&#34;: [y.name] * len(xnames),
            &#34;독립변수&#34;: xnames,
            &#34;B(비표준화 계수)&#34;: np.round(estimator.coef_[0], 4),
            &#34;표준오차&#34;: np.round(se[1:], 3),
            &#34;t&#34;: np.round(t[1:], 4),
            &#34;유의확률&#34;: np.round(p_values[1:], 3),
            &#34;VIF&#34;: vif,
            &#34;OddsRate&#34;: np.round(np.exp(estimator.coef_[0]), 4),
        }
    )

    result_df.sort_values(&#34;VIF&#34;, ascending=False, inplace=True)

    my_pretty_table(result_df)</code></pre>
</details>
</dd>
<dt id="helper.classification.my_classification_multiclass_report"><code class="name flex">
<span>def <span class="ident">my_classification_multiclass_report</span></span>(<span>estimator: <built-in function any>, x: pandas.core.frame.DataFrame = None, y: pandas.core.series.Series = None, sort: str = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>다중로지스틱 회귀분석 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator</code></strong> :&ensp;<code>any</code></dt>
<dd>분류분석 추정기 (모델 객체)</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>독립변수. Defaults to None.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>종속변수. Defaults to None.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification_multiclass_report(
    estimator: any,
    x: DataFrame = None,
    y: Series = None,
    sort: str = None,
) -&gt; None:
    &#34;&#34;&#34;다중로지스틱 회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x (DataFrame, optional): 독립변수. Defaults to None.
        y (Series, optional): 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    class_list = list(estimator.classes_)
    class_size = len(class_list)

    # 추정 확률
    y_pred_proba = estimator.predict_proba(x)

    # 추정확률의 길이(=샘플수)
    n = len(y_pred_proba)

    for i in range(0, class_size):
        # 계수의 수 + 1(절편)
        m = len(estimator.coef_[i]) + 1

        # 절편과 계수를 하나의 배열로 결합
        coefs = np.concatenate([[estimator.intercept_[i]], estimator.coef_[i]])

        # 상수항 추가
        x_full = np.matrix(np.insert(np.array(x), 0, 1, axis=1))

        # 변수의 길이를 활용하여 모든 값이 0인 행렬 생성
        ans = np.zeros((m, m))

        # 표준오차
        for j in range(n):
            ans = (
                ans
                + np.dot(np.transpose(x_full[j, :]), x_full[j, :]) * y_pred_proba[j, i]
            )

        vcov = np.linalg.inv(np.matrix(ans))
        se = np.sqrt(np.diag(vcov))

        # t값
        t = coefs / se

        # p-value
        p_values = (1 - norm.cdf(abs(t))) * 2

        # VIF
        if len(x.columns) &gt; 1:
            vif = [
                variance_inflation_factor(x, list(x.columns).index(v))
                for i, v in enumerate(x.columns)
            ]
        else:
            vif = 0

        # 결과표 생성
        xnames = estimator.feature_names_in_

        result_df = DataFrame(
            {
                &#34;종속변수&#34;: [y.name] * len(xnames),
                &#34;CLASS&#34;: [class_list[i]] * len(xnames),
                &#34;독립변수&#34;: xnames,
                &#34;B(계수)&#34;: np.round(estimator.coef_[i], 4),
                &#34;표준오차&#34;: np.round(se[1:], 3),
                &#34;t&#34;: np.round(t[1:], 4),
                &#34;유의확률&#34;: np.round(p_values[1:], 3),
                &#34;VIF&#34;: vif,
                &#34;OddsRate&#34;: np.round(np.exp(estimator.coef_[i]), 4),
            }
        )

        if sort:
            if sort.upper() == &#34;V&#34;:
                result_df.sort_values(&#34;VIF&#34;, inplace=True)
            elif sort.upper() == &#34;P&#34;:
                result_df.sort_values(&#34;유의확률&#34;, inplace=True)
                pass

        my_pretty_table(result_df)</code></pre>
</details>
</dd>
<dt id="helper.classification.my_classification_report"><code class="name flex">
<span>def <span class="ident">my_classification_report</span></span>(<span>estimator: <built-in function any>, x_train: pandas.core.frame.DataFrame = None, y_train: pandas.core.series.Series = None, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, sort: str = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>분류분석 결과를 이항분류와 다항분류로 구분하여 출력한다. 훈련데이터와 검증데이터가 함께 전달 될 경우 검증 데이터를 우선한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator</code></strong> :&ensp;<code>any</code></dt>
<dd>분류분석 추정기 (모델 객체)</dd>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>훈련 데이터의 독립변수. Defaults to None.</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>훈련 데이터의 종속변수. Defaults to None.</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code>, optional</dt>
<dd>검증 데이터의 독립변수. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code>, optional</dt>
<dd>검증 데이터의 종속변수. Defaults to None.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification_report(
    estimator: any,
    x_train: DataFrame = None,
    y_train: Series = None,
    x_test: DataFrame = None,
    y_test: Series = None,
    sort: str = None,
) -&gt; None:
    &#34;&#34;&#34;분류분석 결과를 이항분류와 다항분류로 구분하여 출력한다. 훈련데이터와 검증데이터가 함께 전달 될 경우 검증 데이터를 우선한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame, optional): 훈련 데이터의 독립변수. Defaults to None.
        y_train (Series, optional): 훈련 데이터의 종속변수. Defaults to None.
        x_test (DataFrame, optional): 검증 데이터의 독립변수. Defaults to None.
        y_test (Series, optional): 검증 데이터의 종속변수. Defaults to None.
        sort (str, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
    &#34;&#34;&#34;
    is_binary = len(estimator.classes_) == 2

    if is_binary:
        if x_test is not None and y_test is not None:
            my_classification_binary_report(estimator, x=x_test, y=y_test, sort=sort)
        else:
            my_classification_binary_report(estimator, x=x_train, y=y_train, sort=sort)
    else:
        if x_test is not None and y_test is not None:
            my_classification_multiclass_report(
                estimator, x=x_test, y=y_test, sort=sort
            )
        else:
            my_classification_multiclass_report(
                estimator, x=x_train, y=y_train, sort=sort
            )</code></pre>
</details>
</dd>
<dt id="helper.classification.my_classification_result"><code class="name flex">
<span>def <span class="ident">my_classification_result</span></span>(<span>estimator: <built-in function any>, x_train: pandas.core.frame.DataFrame = None, y_train: pandas.core.series.Series = None, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, conf_matrix: bool = True, hist: bool = True, roc: bool = True, pr: bool = True, multiclass: str = None, learning_curve: bool = True, cv: int = 10, figsize: tuple = (12, 5), dpi: int = 100) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>회귀분석 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator</code></strong> :&ensp;<code>any</code></dt>
<dd>분류분석 추정기 (모델 객체)</dd>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>conf_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>혼동행렬을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>hist</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>히스토그램을 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>roc</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>ROC Curve를 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>pr</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>PR Curve를 출력할지 여부. Defaults to True.</dd>
<dt><strong><code>multiclass</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>다항분류일 경우, 다항분류 방법(ovo, ovr, None). Defaults to None.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to False.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 10.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (12, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_classification_result(
    estimator: any,
    x_train: DataFrame = None,
    y_train: Series = None,
    x_test: DataFrame = None,
    y_test: Series = None,
    conf_matrix: bool = True,
    hist: bool = True,
    roc: bool = True,
    pr: bool = True,
    multiclass: str = None,
    learning_curve: bool = True,
    cv: int = 10,
    figsize: tuple = (12, 5),
    dpi: int = 100,
) -&gt; None:
    &#34;&#34;&#34;회귀분석 결과를 출력한다.

    Args:
        estimator (any): 분류분석 추정기 (모델 객체)
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        conf_matrix (bool, optional): 혼동행렬을 출력할지 여부. Defaults to True.
        hist (bool, optional): 히스토그램을 출력할지 여부. Defaults to True.
        roc (bool, optional): ROC Curve를 출력할지 여부. Defaults to True.
        pr (bool, optional): PR Curve를 출력할지 여부. Defaults to True.
        multiclass (str, optional): 다항분류일 경우, 다항분류 방법(ovo, ovr, None). Defaults to None.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to False.
        cv (int, optional): 교차검증 횟수. Defaults to 10.
        figsize (tuple, optional): 그래프의 크기. Defaults to (12, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
    &#34;&#34;&#34;

    # ------------------------------------------------------
    # 성능평가

    scores = []
    score_names = []

    # 이진분류인지 다항분류인지 구분
    labels = list(y_train.unique())
    is_binary = len(labels) == 2

    if x_train is not None and y_train is not None:
        # 추정치
        y_train_pred = estimator.predict(x_train)
        y_train_pred_proba = estimator.predict_proba(x_train)
        y_train_pred_proba_1 = y_train_pred_proba[:, 1]

        # 의사결정계수 --&gt; 다항로지스틱에서는 사용 X
        if is_binary:
            y_train_log_loss_test = -log_loss(
                y_train, y_train_pred_proba, normalize=False
            )
            y_train_null = np.ones_like(y_train) * y_train.mean()
            y_train_log_loss_null = -log_loss(y_train, y_train_null, normalize=False)
            y_train_pseudo_r2 = 1 - (y_train_log_loss_test / y_train_log_loss_null)

        # 혼동행렬
        y_train_conf_mat = confusion_matrix(y_train, y_train_pred)

        if is_binary:
            # TN,FP,FN,TP --&gt; 다항로지스틱에서는 사용 X
            ((TN, FP), (FN, TP)) = y_train_conf_mat

            # 성능평가
            # 의사결정계수, 위양성율, 특이성, AUC는 다항로지스틱에서는 사용 불가
            # 나머지 항목들은 코드 변경 예정
            result = {
                &#34;의사결정계수(Pseudo R2)&#34;: y_train_pseudo_r2,
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_train, y_train_pred),
                &#34;정밀도(Precision)&#34;: precision_score(y_train, y_train_pred),
                &#34;재현율(Recall)&#34;: recall_score(y_train, y_train_pred),
                &#34;위양성율(Fallout)&#34;: FP / (TN + FP),
                &#34;특이성(TNR)&#34;: 1 - (FP / (TN + FP)),
                &#34;F1 Score&#34;: f1_score(y_train, y_train_pred),
                &#34;AUC&#34;: roc_auc_score(y_train, y_train_pred_proba_1),
            }
        else:
            result = {
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_train, y_train_pred),
                &#34;정밀도(Precision)&#34;: precision_score(
                    y_train, y_train_pred, average=&#34;macro&#34;
                ),
                &#34;재현율(Recall)&#34;: recall_score(y_train, y_train_pred, average=&#34;macro&#34;),
                &#34;F1 Score&#34;: f1_score(y_train, y_train_pred, average=&#34;macro&#34;),
                &#34;AUC(ovo)&#34;: roc_auc_score(
                    y_train, y_train_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovo&#34;
                ),
                &#34;AUC(ovr)&#34;: roc_auc_score(
                    y_train, y_train_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovr&#34;
                ),
            }
        scores.append(result)
        score_names.append(&#34;훈련데이터&#34;)

    if x_test is not None and y_test is not None:
        # 추정치
        y_test_pred = estimator.predict(x_test)
        y_test_pred_proba = estimator.predict_proba(x_test)
        y_test_pred_proba_1 = y_test_pred_proba[:, 1]

        if is_binary:
            # 의사결정계수
            y_test_log_loss_test = -log_loss(y_test, y_test_pred_proba, normalize=False)
            y_test_null = np.ones_like(y_test) * y_test.mean()
            y_test_log_loss_null = -log_loss(y_test, y_test_null, normalize=False)
            y_test_pseudo_r2 = 1 - (y_test_log_loss_test / y_test_log_loss_null)

        # 혼동행렬
        y_test_conf_mat = confusion_matrix(y_test, y_test_pred)

        if is_binary:
            # TN,FP,FN,TP
            ((TN, FP), (FN, TP)) = y_test_conf_mat

            # 성능평가
            result = {
                &#34;의사결정계수(Pseudo R2)&#34;: y_test_pseudo_r2,
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_test, y_test_pred),
                &#34;정밀도(Precision)&#34;: precision_score(y_test, y_test_pred),
                &#34;재현율(Recall)&#34;: recall_score(y_test, y_test_pred),
                &#34;위양성율(Fallout)&#34;: FP / (TN + FP),
                &#34;특이성(TNR)&#34;: 1 - (FP / (TN + FP)),
                &#34;F1 Score&#34;: f1_score(y_test, y_test_pred),
                &#34;AUC&#34;: roc_auc_score(y_test, y_test_pred_proba_1),
            }
        else:
            result = {
                &#34;정확도(Accuracy)&#34;: accuracy_score(y_test, y_test_pred),
                &#34;정밀도(Precision)&#34;: precision_score(
                    y_test, y_test_pred, average=&#34;macro&#34;
                ),
                &#34;재현율(Recall)&#34;: recall_score(y_test, y_test_pred, average=&#34;macro&#34;),
                &#34;F1 Score&#34;: f1_score(y_test, y_test_pred, average=&#34;macro&#34;),
                &#34;AUC(ovo)&#34;: roc_auc_score(
                    y_test, y_test_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovo&#34;
                ),
                &#34;AUC(ovr)&#34;: roc_auc_score(
                    y_test, y_test_pred_proba, average=&#34;macro&#34;, multi_class=&#34;ovr&#34;
                ),
            }

        scores.append(result)
        score_names.append(&#34;검증데이터&#34;)

    if is_binary:
        # 각 항목의 설명 추가
        result = {
            &#34;의사결정계수(Pseudo R2)&#34;: &#34;로지스틱회귀의 성능 측정 지표로, 1에 가까울수록 좋은 모델&#34;,
            &#34;정확도(Accuracy)&#34;: &#34;예측 결과(TN,FP,TP,TN)가 실제 결과(TP,TN)와 일치하는 정도&#34;,
            &#34;정밀도(Precision)&#34;: &#34;양성으로 예측한 결과(TP,FP) 중 실제 양성(TP)인 비율&#34;,
            &#34;재현율(Recall)&#34;: &#34;실제 양성(TP,FN) 중 양성(TP)으로 예측한 비율&#34;,
            &#34;위양성율(Fallout)&#34;: &#34;실제 음성(FP,TN) 중 양성(FP)으로 잘못 예측한 비율&#34;,
            &#34;특이성(TNR)&#34;: &#34;실제 음성(FP,TN) 중 음성(TN)으로 정확히 예측한 비율&#34;,
            &#34;F1 Score&#34;: &#34;정밀도와 재현율의 조화평균&#34;,
            &#34;AUC&#34;: &#34;ROC Curve의 밑면적으로, 1에 가까울수록 좋은 모델&#34;,
        }
    else:
        result = {
            &#34;정확도(Accuracy)&#34;: &#34;예측 결과(TN,FP,TP,TN)가 실제 결과(TP,TN)와 일치하는 정도&#34;,
            &#34;정밀도(Precision)&#34;: &#34;양성으로 예측한 결과(TP,FP) 중 실제 양성(TP)인 비율&#34;,
            &#34;재현율(Recall)&#34;: &#34;실제 양성(TP,FN) 중 양성(TP)으로 예측한 비율&#34;,
            &#34;F1 Score&#34;: &#34;정밀도와 재현율의 조화평균&#34;,
            &#34;AUC(ovo)&#34;: &#34;ROC Curve의 밑면적으로, 1에 가까울수록 좋은 모델&#34;,
            &#34;AUC(ovr)&#34;: &#34;ROC Curve의 밑면적으로, 1에 가까울수록 좋은 모델&#34;,
        }

    scores.append(result)
    score_names.append(&#34;설명&#34;)

    print(&#34;[분류분석 성능평가]&#34;)
    result_df = DataFrame(scores, index=score_names)
    my_pretty_table(result_df.T)

    # ------------------------------------------------------
    # 혼동행렬
    if conf_matrix:
        print(&#34;\n[혼동행렬]&#34;)

        if x_test is not None and y_test is not None:
            my_confusion_matrix(y_test, y_test_pred, figsize=figsize, dpi=dpi)
        else:
            my_confusion_matrix(y_train, y_train_pred, figsize=figsize, dpi=dpi)

    # ------------------------------------------------------
    # curve
    print(&#34;\n[Roc Curve]&#34;)

    if x_test is None or y_test is None:
        my_roc_curve(
            estimator,
            x_train,
            y_train,
            hist=hist,
            roc=roc,
            pr=pr,
            multiclass=multiclass,
            dpi=dpi,
        )
    else:
        my_roc_curve(
            estimator,
            x_test,
            y_test,
            hist=hist,
            roc=roc,
            pr=pr,
            multiclass=multiclass,
            dpi=dpi,
        )
    # 학습곡선
    if learning_curve:
        print(&#34;\n[학습곡선]&#34;)
        yname = y_train.name

        if x_test is not None and y_test is not None:
            y_df = concat([y_train, y_test])
            x_df = concat([x_train, x_test])
        else:
            y_df = y_train.copy()
            x_df = x_train.copy()

        x_df[yname] = y_df
        x_df.sort_index(inplace=True)

        if cv &gt; 0:
            my_learing_curve(
                estimator, data=x_df, yname=yname, cv=cv, figsize=figsize, dpi=dpi
            )
        else:
            my_learing_curve(
                estimator, data=x_df, yname=yname, figsize=figsize, dpi=dpi
            )</code></pre>
</details>
</dd>
<dt id="helper.classification.my_logistic_classification"><code class="name flex">
<span>def <span class="ident">my_logistic_classification</span></span>(<span>x_train: pandas.core.frame.DataFrame, y_train: pandas.core.series.Series, x_test: pandas.core.frame.DataFrame = None, y_test: pandas.core.series.Series = None, cv: int = 5, learning_curve=True, report: bool = True, figsize=(10, 5), dpi: int = 100, sort: str = None, params: dict = {'penalty': ['l1', 'l2', 'elasticnet'], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}) ‑> sklearn.linear_model._logistic.LogisticRegression</span>
</code></dt>
<dd>
<div class="desc"><p>로지스틱 회귀분석을 수행하고 결과를 출력한다.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 훈련 데이터</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 훈련 데이터</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>독립변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>Series</code></dt>
<dd>종속변수에 대한 검증 데이터. Defaults to None.</dd>
<dt><strong><code>cv</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>교차검증 횟수. Defaults to 5.</dd>
<dt><strong><code>learning_curve</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>학습곡선을 출력할지 여부. Defaults to True.</dd>
<dt>report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.</dt>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>그래프의 크기. Defaults to (10, 5).</dd>
<dt><strong><code>dpi</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>그래프의 해상도. Defaults to 100.</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>독립변수 결과 보고 표의 정렬 기준 (v, p)</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>하이퍼파라미터. Defaults to {'penalty': ['l1', 'l2', 'elasticnet'], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>LogisticRegression</code></dt>
<dd>회귀분석 모델</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def my_logistic_classification(
    x_train: DataFrame,
    y_train: Series,
    x_test: DataFrame = None,
    y_test: Series = None,
    cv: int = 5,
    learning_curve=True,
    report: bool = True,
    figsize=(10, 5),
    dpi: int = 100,
    sort: str = None,
    params: dict = {
        &#34;penalty&#34;: [&#34;l1&#34;, &#34;l2&#34;, &#34;elasticnet&#34;],
        &#34;C&#34;: [0.001, 0.01, 0.1, 1, 10, 100],
    },
) -&gt; LogisticRegression:
    &#34;&#34;&#34;로지스틱 회귀분석을 수행하고 결과를 출력한다.

    Args:
        x_train (DataFrame): 독립변수에 대한 훈련 데이터
        y_train (Series): 종속변수에 대한 훈련 데이터
        x_test (DataFrame): 독립변수에 대한 검증 데이터. Defaults to None.
        y_test (Series): 종속변수에 대한 검증 데이터. Defaults to None.
        cv (int, optional): 교차검증 횟수. Defaults to 5.
        learning_curve (bool, optional): 학습곡선을 출력할지 여부. Defaults to True.
        report (bool, optional) : 독립변수 보고를 출력할지 여부. Defaults to True.
        figsize (tuple, optional): 그래프의 크기. Defaults to (10, 5).
        dpi (int, optional): 그래프의 해상도. Defaults to 100.
        sort (bool, optional): 독립변수 결과 보고 표의 정렬 기준 (v, p)
        params (dict, optional): 하이퍼파라미터. Defaults to {&#39;penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;, &#39;elasticnet&#39;], &#39;C&#39;: [0.001, 0.01, 0.1, 1, 10, 100]}.
    Returns:
        LogisticRegression: 회귀분석 모델
    &#34;&#34;&#34;
    # ------------------------------------------------------
    # 분석모델 생성

    # 교차검증 설정
    if cv &gt; 0:
        prototype_estimator = LogisticRegression(max_iter=500, n_jobs=-1)
        grid = GridSearchCV(prototype_estimator, param_grid=params, cv=cv, n_jobs=-1)
        grid.fit(x_train, y_train)

        result_df = DataFrame(grid.cv_results_[&#34;params&#34;])
        result_df[&#34;mean_test_score&#34;] = grid.cv_results_[&#34;mean_test_score&#34;]

        print(&#34;[교차검증]&#34;)
        my_pretty_table(
            result_df.dropna(subset=[&#34;mean_test_score&#34;]).sort_values(
                by=&#34;mean_test_score&#34;, ascending=False
            )
        )
        print(&#34;&#34;)

        estimator = grid.best_estimator_
        estimator.best_params = grid.best_params_
    else:
        estimator = LogisticRegression(max_iter=500, n_jobs=-1)
        estimator.fit(x_train, y_train)

    # ------------------------------------------------------
    # 결과값 생성

    # 훈련 데이터에 대한 추정치 생성
    y_pred = (
        estimator.predict(x_test) if x_test is not None else estimator.predict(x_train)
    )
    y_pred_prob = (
        estimator.predict_proba(x_test)
        if x_test is not None
        else estimator.predict_proba(x_train)
    )

    # 도출된 결과를 모델 객체에 포함시킴
    estimator.x = x_test if x_test is not None else x_train
    estimator.y = y_test if y_test is not None else y_train
    estimator.y_pred = y_pred if y_test is not None else estimator.predict(x_train)
    estimator.y_pred_proba = (
        y_pred_prob if y_test is not None else estimator.predict_proba(x_train)
    )

    # ------------------------------------------------------
    # 성능평가
    if x_test is not None and y_test is not None:
        my_classification_result(
            estimator,
            x_train=x_train,
            y_train=y_train,
            x_test=x_test,
            y_test=y_test,
            learning_curve=learning_curve,
            cv=cv,
            figsize=figsize,
            dpi=dpi,
        )
    else:
        my_classification_result(
            estimator,
            x_train=x_train,
            y_train=y_train,
            learning_curve=learning_curve,
            cv=cv,
            figsize=figsize,
            dpi=dpi,
        )

    # ------------------------------------------------------
    # 보고서 출력
    if report:
        my_classification_report(estimator, x_train, y_train, x_test, y_test, sort)

    return estimator</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="helper" href="index.html">helper</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="helper.classification.my_classification_binary_report" href="#helper.classification.my_classification_binary_report">my_classification_binary_report</a></code></li>
<li><code><a title="helper.classification.my_classification_multiclass_report" href="#helper.classification.my_classification_multiclass_report">my_classification_multiclass_report</a></code></li>
<li><code><a title="helper.classification.my_classification_report" href="#helper.classification.my_classification_report">my_classification_report</a></code></li>
<li><code><a title="helper.classification.my_classification_result" href="#helper.classification.my_classification_result">my_classification_result</a></code></li>
<li><code><a title="helper.classification.my_logistic_classification" href="#helper.classification.my_logistic_classification">my_logistic_classification</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>